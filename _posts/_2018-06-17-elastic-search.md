---
title: Полнотекстовый поиск с Elastic Search
header:
  teaser: images/elastic-search/search_example.png
excerpt: Несколько рецептов приготовления
date: '2018-06-17 00:00:00'
---

План:
6. Простой автокомплит - match vs phrase prefix. Нужен порядок VS не нужен. Про max_expansions
7. Фишки анализа
  - Ngram'ы - чтобы искалось по подстрокам тоже
  - Поиск по телефонам
  - Ё-е
8. Переключение раскладки
9. Релевантность - упорядочить по типу сущности. Альтернативы - группировки. Когда Boost не работает. Constant score.

Вычитать текст.
Сжать картинки

---

В проекте, которым я занимаюсь в [Контуре](https://kontur.ru/), мы решили сделать полнотекстовый поиск по основным сущностям системы. Мы не изобрели велосипед — взяли [Elastic Search](https://www.elastic.co/products/elasticsearch) и дотюнили до наших нужд. Elastic Search дает богатые возможности для полнотекстового поиска, предоставляет шардирование и репликацию данных, в общем — классный инструмент. Логика поиска с использованием Elastic умещается всего в несколько сотен строк кода. Код компактный, но за ним спрятаны лютые хаки и понимание устройства Elastic Search. В статье хочу рассказать о парочке фишек в организации поиска.

## Что ищем

Мой проект — это внутренний биллинг компании (Контур.Биллинг), один из пользователей — продавцы. Продавцу нужно быстро найти клиента в нашей системе по любой информации, которая у него есть — ФИО, номер телефона, email, ИНН, номер заказа. Для продавца поиск выглядит примерно так:

![Пример поискового запроса](/images/elastic-search/search_example.png 'Пример поискового запроса'){: .align-center}

Строка поиска — обычный autocomplete. Пока пользователь набирает запрос, всплывают подсказки с найденными клиентами.

Кроме записей о клиенте, в поиске ищут заявки по работе с клиентом, заказы, контакты, счета, юридические документы и прочее.

Для каждой сущности системы мы храним документ из нескольких полей:
  - Текст, по которому можно найти документ;
  - Мета-информация о документе — например, тип документа;
  - Список пользователей, которые могут видеть документ.

Текст по-разному формируется для разных сущностей — по клиенту это ИНН-КПП клиента и название организации (Контур работает в B2B, поэтому большинство клиентов идентифицируются по реквизитам), для заявки — ФИО клиента и телефон, который он оставил в заявке, и так далее.

## Индексирование данных

Данные в Биллинге хранятся в нескольких базах данных, в основном — в&nbsp;Microsoft SQL и Apache Cassandra. Есть индексирующий процесс, который просыпается по [расписанию](https://ru.wikipedia.org/wiki/Cron), вычитывает изменившиеся данные из базы, отправляет их в Elastic. Elastic хранит лишь копию данных, необходимых для поиска.

В чем плюсы такого подхода:
  - В отличие от синхронной записи (записали в БД — сразу записали в Elastic) получаем дополнительную отказоустойчивость. Бывает так, что Elastic тупит и не может записать данные ([долго собирает мусор](https://ru.wikipedia.org/wiki/%D0%A1%D0%B1%D0%BE%D1%80%D0%BA%D0%B0_%D0%BC%D1%83%D1%81%D0%BE%D1%80%D0%B0), [тупанула сеть](https://aphyr.com/posts/288-the-network-is-reliable)). Что делать при синхронной записи неясно — данные уже есть в БД, а в Elastic нет, транзакционно записать в Elastic нельзя. Асинхронный процесс гарантирует [eventual consistency](https://en.wikipedia.org/wiki/Eventual_consistency) — данные в конечном счете окажутся в Elastic. Если не получилось записать сразу, то процесс повторит попытку позже;
  - Elastic не используется как первичное хранилище. Данные можно безболезненно потерять и пересобрать индекс заново. Пару раз это здорово выручало меня, когда делал изменение схемы данных — я забил на поддержку обратной совместимости, создал новый индекс, накачал его данными и переключил пользователей на чтение из нового индекса.

В чем минусы:
  - Есть задержка на появление данных в поиске, поскольку индексирующий процесс работает по расписанию. Задержку можно уменьшать, настраивая время запуска процесса;
  - Конкретно в нашей однопоточной схеме — индексация слишком медленная, если данных много. В Биллинге небольшой индекс на десятки гигабайт и несколько десятков миллионов документов. Его индексация занимает 10-12 часов. Не слишком быстро — но пока нас устраивает.

Есть прикольный альтернативный подход к индексации с помощью очереди сообщений — записываем все события по изменению сущностей в очередь [Kafka](http://kafka.apache.org/), а потом несколько индексирующих процессов разгребают очередь сообщений и индексируют документы в Elastic. Подход с очередью лучше масштабируется. Пример индексации с помощью очереди можно посмотреть на [Github](https://github.com/BigDataDevs/kafka-elasticsearch-consumer).

## Анализ текста

Основная структура данных в Elastic — это [инвертированный индекс](https://ru.wikipedia.org/wiki/%D0%98%D0%BD%D0%B2%D0%B5%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%BD%D1%8B%D0%B9_%D0%B8%D0%BD%D0%B4%D0%B5%D0%BA%D1%81). Это индекс, который по каждому слову запоминает, в каких документах оно встречается.

![Инвертированный индекс](/images/elastic-search/inverted-index.svg 'Инвертированный индекс'){: .align-center}

Такой индекс эффективен, когда мы ищем документы с вхождением слова. Если нужно найти вхождения комбинации слов, то можно взять списки для каждого слова и пересечь их.

Чтобы построить такой индекс, Elastic прогоняет текст через несколько шагов: 

![Этапы анализа](/images/elastic-search/analysis.png 'Этапы анализа'){: .align-center}

1. CharFilter — фильтрация входных данных. Здесь отбрасываются символы, которые не несут полезной информации для поиска, например, служебные символы, html-верстка.
  2. Tokenizer — токенизация или разбиение текста на слова. 
  3. TokenFilter — преобразование полученых слов. Например, каждое слово можно привести к нижнему регистру или заменить на слово-синоним. Можно вообще выкинуть слово из индекса, например, если это нецензурное слово.

## Поиск

Filter & query

Релевантность

## Авторизация запроса

Биллинг хранит чувствительные данные компании. Поэтому любой запрос пользователя авторизуется. Для авторизации доступа к документам в поиске мы используем паттерн Access Control List.

[Access Control List](https://ru.wikipedia.org/wiki/ACL) (ACL) — паттерн для избирательного предоставления доступа к документу. В документе мы сохраняем список пользователей, которым доступен этот документ. В Биллинге размер ACL ограничен десятком пользователей, поэтому документ получается не слишком пухлый. Авторизация по ACL делается так — к любому запросу пользователя в Elastic добавляется запрос по вложеному документу [(Nested query)](https://www.elastic.co/guide/en/elasticsearch/reference/6.0//query-dsl-nested-query.html).

Пример фильтра:
```json
{
  "filter": [{
    "nested": {
      "path": "accessControlList",
      "query": {
        "bool": {
          "filter": [{
            "term": {
              "accessControlList.userId": {
                "value": "d32c608c4d484a058bcf759e3c68eb28"
              }
            }
          }]
        }
      }
    }
  }]
}
```

В Nested-фильтре указан путь `path` до вложенного документа. Во вложенном запросе фильтруем по `userId` — идентификатору пользователя.

## "Объясни" — API 

Для неискушенного инженера поиск в Elastic работает как магия. Иногда категорически непонятно, почему документ подошел под критерии поиска. Мне кажется, я потратил человеко-дни на медитацию над некоторыми запросами, когда только начинал изучать Elastic.

Чтобы понимать работу Elastic, не нужно разбираться в его исходниках. Разработчики дали два удобных API:
  - [Analyze API](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-analyze.html) — прогоняет текст через указанный анализатор и показывает, какие слова Elastic сохранит в индекс.
  - [Explain API](https://www.elastic.co/guide/en/elasticsearch/reference/6.3/search-explain.html) - объясняет, почему документ подходит или не подходит под критерии поиска, показывает релевантность документа и как она вычислена. 

Я использую эти API для отладки:
  - Если настраиваю свой анализатор и хочу проверить, как она работает (особенно если где-то фигурируют регулярные выражения);
  - Когда поиск не находит нужный документ или находит лишний;
  - Когда находятся правильные документы, но более релевантные оказываются в выдаче ниже менее релевантных. Тогда лезу в&nbsp;Explain&nbsp;API и зарываюсь в формулу расчета релевантности.

---

Как организовать самый простой автокомплит
  - Фигачишь match
  - Фигачишь PhrasePrefix - если важен порядок слов (вдруг)
  - Рассказать про устройство работы и max_expansions
    https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query-phrase-prefix.html

Как авторизовать пользователя
  - ACL - access control list
  - Nested запросы

Почему конвеер - крутой инструмент
  - Рассказ про поиск по подстроке - как организовать? Добавим ngram'ы к существующему поиску
  - Нюансы с телефонами
  - Нюансы с e и ё
  - Можно пойти дальше - эластик умеет заменять синонимы, делать стемминг, выбрасывать стоп-слова и т.д.
  - Проблема - кривая раскладка
    - Можно решать средствами эластика (char filter на уровне запроса) - но исторически у нас хардкод и делаем два запроса :)

  - Рассказать, как все это решается с помощью конвеера

Другая проблема пользователя - хотим видеть какие-то сущности чаще
  - Альтернативное решение - UI с группировкой, автоматически открывать самую полезную вкладку по контексту
  - Как поднимаем релевантность. Сценарии пользователя - поднимать СЦ, поднимать клиентов, поднимать счета

Проблемы с boost'ом
  - Записать гифку с поиском по слову "Ракитянская" и плящущей выдачей
 
Проблема
  - Посмотреть на explain
  - Проанализировать, от чего зависит TF-IDF. Показать, почему не подходит в нашем случае

Решения
  - Изменить интерфейс - показывать разделы с группировкой и счетчиками, например
  - Constant-score
  - Решили остановиться на constant-score, потому что задача неважная здесь и сейчас, не хотим переделывать интерфейс. Не все должно работать идеально, есть куча здаач в сервисе, которые намного важнее, чем переделывать то, что работаем и не парит пользователя.

Тюнинг
  - Заменям на constant-score все
  - Добавлем scoring для одинаковых сущностей
  - Показать, как выбрать веса так, чтобы все еще оставалась детерменированная работа

Выводы
  - У эластика мощная модель по умолчанию - ушло чертовски мало времени, чтобы это все искалось
  - Не всегда нужен инструмент tf-idf - для некоторых запросов это просто глупо :)

TF-IDF - мера для ранжирования документов. Пример - допустим мы собрали архив статей о путешествиях в разные страны (блоги, репортажи, гайды и т.д.) и хотим сделать поисковую строку в стиле Google. Пользователь вводит запрос "винные дороги Кахетии". Как определить, какая статья больше подходит под запрос пользователя?

TF-IDF считает рейтинг каждого документа, где встречаются такие слова. Рейтинг считается как произведение двух величин:
  - TF (termin frequency) - то, как часто слово встречается в документе (в сравнении с общим числом слов)
  - IDF (inverse document frequency) - то, насколько уникально слово в коллекции документов. Чем уникальнее и реже, тем лучше.
TF-IDF будет поднимать в выдаче документы, в которых часто встречается слово "Кахетия" - оно встречается редко и, скорей всего, в таких документах есть то, что нужно. Слово "дороги" будет меньше влиять на рейтинг документа - так как в статьях о путешествиях встречается широко, а значит и плохо помогает отличить статьи о винных дорогах Кахетии от статей об автостопе по Франции.

В Эластике используется модификация TF-IDF.
tf(t in d) = √frequency (square root)
idf(t) = 1 + log ( numDocs / (docFreq + 1)) // docFreq - как часто встречается в документах
norm(d) = 1 / √numTerms (отключаемая штука)

В каких пределах исчисляется эта штука?
- tf хорошо бы в 1 (можно оставлять уникальный термы). Плюс у нас индекс такой, что там редко бывает что-то сильно больше
- idf
  - Для плательщиков - 1 + log (30 млн / (5 млн + 1)) = 1 + log 6 ~ 3.5
  - Для счетов - 1 + log (30 млн / (15 млн + 1)) = 1 + log 2 = 2
  - Для ПП - 1 + log (30 млн / 3 млн) = 1 + log 10 ~ 4.1
  - Короче, чем реже, тем лучше
- norm
  - для счетов - терм всего один + анализируется. 
  - для плательщиков - инн/кпп + название.
  - для ПП - инн/кпп + название + длинный список контактов. 
Взять примеры tf-idf с боевой, показать, что коэффициент norm очень сильно перевешивает 

Для запроса из одного слова посчитать TF-IDF довольно легко. Как посчитать, когда запрос состоит из нескольких слов: 

score(q,d)  = queryNorm(q) · coord(q,d) · ∑ ( tf(t in d) · idf(t)² · t.getBoost() · norm(t,d) ) (t in q)    

queryNorm - не зависит от документа, нужен только для сравнения результатов разных запросов друг с другом. Про него говорить не будем.

coord(q,d) = number of matching terms(q,d) / total terms (q)
Когда в should несколько слов, то поднимает выше те, где больше слов встретилось. Тоже забьем на него

t.getBoost() - вес, который мы прописали терму

Видим, что getBoost - это какая-то константа, а norm отличается разительно в зависимости от данных. 

Короче, это плохая затея делать boost по типам сущностей - для них проще задать предсказуемый constantScore. И еще добавлять constantScore, если совпало точно. 

Если сущности совпадают - окей, тогда давайте прибавим score. 

## С чего все началось

