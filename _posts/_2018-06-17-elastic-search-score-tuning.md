---
title: Задачка про полнотекстовый поиск
header:
  teaser: images/gtd/teaser.jpg
excerpt: Готовим эластик
date: '2018-06-17 00:00:00'
---

Мотивация - в моем проекте есть небольшой класс, отвечающий за полнотекстовый поиск. Логика поиска умещается в 100 с небольшим строк кода. Но за этим стоит столько нюансов, что хватит на статью :)

Цель доклада - показать, насколько эластик мощный инструмент, продемонстрировать самый безумный сценарий использования (пока что).

Если вы не знаете, что такое эластик - посмотрите статью. Или презентацию из предыдущего поста.

Рассказать про проблему
  - Показать, как выглядит поиск, почему так
  - Модель документа. Какие типы сущностей есть

Как диагностировать - explain на запись и чтение

Как организовать самый простой автокомплит
  - Фигачишь PhrasePrefix. 
  - Рассказать про устройство работы и max_expansions
    https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query-phrase-prefix.html

Как авторизовать пользователя
  - ACL - access control list
  - Nested запросы

Почему конвеер - крутой инструмент
  - Рассказ про поиск по подстроке - как организовать? Добавим ngram'ы к существующему поиску
  - Нюансы с телефонами
  - Нюансы с e и ё
  - Можно пойти дальше - эластик умеет заменять синонимы, делать стемминг, выбрасывать стоп-слова и т.д.
  - Проблема - кривая раскладка
    - Можно решать средствами эластика (char filter на уровне запроса) - но исторически у нас хардкод и делаем два запроса :)

  - Рассказать, как все это решается с помощью конвеера

Хайлайт
  - 

Другая проблема пользователя - хотим видеть какие-то сущности чаще
  - Альтернативное решение - UI с группировкой, автоматически открывать самую полезную вкладку по контексту
  - Как поднимаем релевантность. Сценарии пользователя - поднимать СЦ, поднимать клиентов, поднимать счета

Проблемы с boost'ом
  - Записать гифку с поиском по слову "Ракитянская" и плящущей выдачей
 
Проблема
  - Посмотреть на explain
  - Проанализировать, от чего зависит TF-IDF. Показать, почему не подходит в нашем случае

Решения
  - Изменить интерфейс - показывать разделы с группировкой и счетчиками, например
  - Constant-score
  - Решили остановиться на constant-score, потому что задача неважная здесь и сейчас, не хотим переделывать интерфейс. Не все должно работать идеально, есть куча здаач в сервисе, которые намного важнее, чем переделывать то, что работаем и не парит пользователя.

Тюнинг
  - Заменям на constant-score все
  - Добавлем scoring для одинаковых сущностей
  - Показать, как выбрать веса так, чтобы все еще оставалась детерменированная работа

Выводы
  - У эластика мощная модель по умолчанию - ушло чертовски мало времени, чтобы это все искалось
  - Не всегда нужен инструмент tf-idf - для некоторых запросов это просто глупо :)

TF-IDF - мера для ранжирования документов. Пример - допустим мы собрали архив статей о путешествиях в разные страны (блоги, репортажи, гайды и т.д.) и хотим сделать поисковую строку в стиле Google. Пользователь вводит запрос "винные дороги Кахетии". Как определить, какая статья больше подходит под запрос пользователя?

TF-IDF считает рейтинг каждого документа, где встречаются такие слова. Рейтинг считается как произведение двух величин:
  - TF (termin frequency) - то, как часто слово встречается в документе (в сравнении с общим числом слов)
  - IDF (inverse document frequency) - то, насколько уникально слово в коллекции документов. Чем уникальнее и реже, тем лучше.
TF-IDF будет поднимать в выдаче документы, в которых часто встречается слово "Кахетия" - оно встречается редко и, скорей всего, в таких документах есть то, что нужно. Слово "дороги" будет меньше влиять на рейтинг документа - так как в статьях о путешествиях встречается широко, а значит и плохо помогает отличить статьи о винных дорогах Кахетии от статей об автостопе по Франции.

В Эластике используется модификация TF-IDF.
tf(t in d) = √frequency (square root)
idf(t) = 1 + log ( numDocs / (docFreq + 1)) // docFreq - как часто встречается в документах
norm(d) = 1 / √numTerms (отключаемая штука)

В каких пределах исчисляется эта штука?
- tf хорошо бы в 1 (можно оставлять уникальный термы). Плюс у нас индекс такой, что там редко бывает что-то сильно больше
- idf
  - Для плательщиков - 1 + log (30 млн / (5 млн + 1)) = 1 + log 6 ~ 3.5
  - Для счетов - 1 + log (30 млн / (15 млн + 1)) = 1 + log 2 = 2
  - Для ПП - 1 + log (30 млн / 3 млн) = 1 + log 10 ~ 4.1
  - Короче, чем реже, тем лучше
- norm
  - для счетов - терм всего один + анализируется. 
  - для плательщиков - инн/кпп + название.
  - для ПП - инн/кпп + название + длинный список контактов. 
Взять примеры tf-idf с боевой, показать, что коэффициент norm очень сильно перевешивает 

Для запроса из одного слова посчитать TF-IDF довольно легко. Как посчитать, когда запрос состоит из нескольких слов: 

score(q,d)  = queryNorm(q) · coord(q,d) · ∑ ( tf(t in d) · idf(t)² · t.getBoost() · norm(t,d) ) (t in q)    

queryNorm - не зависит от документа, нужен только для сравнения результатов разных запросов друг с другом. Про него говорить не будем.

coord(q,d) = number of matching terms(q,d) / total terms (q)
Когда в should несколько слов, то поднимает выше те, где больше слов встретилось. Тоже забьем на него

t.getBoost() - вес, который мы прописали терму

Видим, что getBoost - это какая-то константа, а norm отличается разительно в зависимости от данных. 

Короче, это плохая затея делать boost по типам сущностей - для них проще задать предсказуемый constantScore. И еще добавлять constantScore, если совпало точно. 

Если сущности совпадают - окей, тогда давайте прибавим score. 

## С чего все началось

